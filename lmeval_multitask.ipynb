{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "89bda0a9",
      "metadata": {},
      "source": [
        "# lmeval_multitask\n",
        "\n",
        "런타임 유형: L4 or A100 으로 설정하기\n",
        "\n",
        "실행 순서:\n",
        "1. 패키지 설치\n",
        "2. Google Drive 마운트\n",
        "3. 설정값(특히 `MODEL_PATH`) 확인\n",
        "4. (선택) `lm_eval --tasks list`로 태스크 확인\n",
        "5. 태스크 실행 셀 4개를 순서대로 실행\n",
        "\n",
        "참고:\n",
        "- 태스크 실행 셀은 `TASK_NAME`만 다릅니다.\n",
        "- 결과는 `RUN_DIR/<task_name>` 경로에 저장됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df1972ab",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 런타임 재시작 후 실행 권장\n",
        "%pip install -U pip\n",
        "%pip install -U \"lm-eval[vllm]\" langdetect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "616b1aae",
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06eaad1a",
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime, timezone\n",
        "from pathlib import Path\n",
        "\n",
        "MODEL_PATH = \"/content/drive/MyDrive/LGAimers/base_model\"  # 필요 시 수정\n",
        "OUTPUT_ROOT = \"/content/drive/MyDrive/LGAimers/lm_eval_multitask_results\"\n",
        "RUN_NAME = f\"multitask_{datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')}\"\n",
        "\n",
        "TRUST_REMOTE_CODE = True\n",
        "ENABLE_THINKING = False\n",
        "TENSOR_PARALLEL_SIZE = 1\n",
        "GPU_MEMORY_UTILIZATION = 0.85\n",
        "BATCH_SIZE = \"auto\"\n",
        "MAX_GEN_TOKS = 16384\n",
        "APPLY_CHAT_TEMPLATE = True\n",
        "\n",
        "RUN_DIR = Path(OUTPUT_ROOT) / RUN_NAME\n",
        "RUN_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"MODEL_PATH: {MODEL_PATH}\")\n",
        "print(f\"RUN_DIR: {RUN_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d263b4ee",
      "metadata": {},
      "outputs": [],
      "source": [
        "TASK_NAME = \"ifeval\"\n",
        "!lm_eval \\\n",
        "  --model vllm \\\n",
        "  --model_args pretrained={MODEL_PATH},trust_remote_code={str(TRUST_REMOTE_CODE).lower()},enable_thinking={str(ENABLE_THINKING).lower()},tensor_parallel_size={TENSOR_PARALLEL_SIZE},gpu_memory_utilization={GPU_MEMORY_UTILIZATION} \\\n",
        "  --tasks {TASK_NAME} \\\n",
        "  --batch_size {BATCH_SIZE} \\\n",
        "  --apply_chat_template {APPLY_CHAT_TEMPLATE} \\\n",
        "  --gen_kwargs max_gen_toks={MAX_GEN_TOKS} \\\n",
        "  --output_path {RUN_DIR}/{TASK_NAME}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "613cf966",
      "metadata": {},
      "outputs": [],
      "source": [
        "TASK_NAME = \"mmlu_redux_generative\"\n",
        "!lm_eval \\\n",
        "  --model vllm \\\n",
        "  --model_args pretrained={MODEL_PATH},trust_remote_code={str(TRUST_REMOTE_CODE).lower()},enable_thinking={str(ENABLE_THINKING).lower()},tensor_parallel_size={TENSOR_PARALLEL_SIZE},gpu_memory_utilization={GPU_MEMORY_UTILIZATION} \\\n",
        "  --tasks {TASK_NAME} \\\n",
        "  --batch_size {BATCH_SIZE} \\\n",
        "  --apply_chat_template {APPLY_CHAT_TEMPLATE} \\\n",
        "  --gen_kwargs max_gen_toks={MAX_GEN_TOKS} \\\n",
        "  --output_path {RUN_DIR}/{TASK_NAME}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34928726",
      "metadata": {},
      "outputs": [],
      "source": [
        "TASK_NAME = \"gsm8k\"\n",
        "!lm_eval \\\n",
        "  --model vllm \\\n",
        "  --model_args pretrained={MODEL_PATH},trust_remote_code={str(TRUST_REMOTE_CODE).lower()},enable_thinking={str(ENABLE_THINKING).lower()},tensor_parallel_size={TENSOR_PARALLEL_SIZE},gpu_memory_utilization={GPU_MEMORY_UTILIZATION} \\\n",
        "  --tasks {TASK_NAME} \\\n",
        "  --batch_size {BATCH_SIZE} \\\n",
        "  --apply_chat_template {APPLY_CHAT_TEMPLATE} \\\n",
        "  --gen_kwargs max_gen_toks={MAX_GEN_TOKS} \\\n",
        "  --output_path {RUN_DIR}/{TASK_NAME}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a4e8149",
      "metadata": {},
      "outputs": [],
      "source": [
        "TASK_NAME = \"hrm8k_ksm\"\n",
        "!lm_eval \\\n",
        "  --model vllm \\\n",
        "  --model_args pretrained={MODEL_PATH},trust_remote_code={str(TRUST_REMOTE_CODE).lower()},enable_thinking={str(ENABLE_THINKING).lower()},tensor_parallel_size={TENSOR_PARALLEL_SIZE},gpu_memory_utilization={GPU_MEMORY_UTILIZATION} \\\n",
        "  --tasks {TASK_NAME} \\\n",
        "  --batch_size {BATCH_SIZE} \\\n",
        "  --apply_chat_template {APPLY_CHAT_TEMPLATE} \\\n",
        "  --gen_kwargs max_gen_toks={MAX_GEN_TOKS} \\\n",
        "  --output_path {RUN_DIR}/{TASK_NAME}\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
